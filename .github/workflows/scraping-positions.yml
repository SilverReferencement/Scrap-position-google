name: Scraping Positions Google

on:
  # ExÃ©cution hebdomadaire : tous les lundis Ã  8h00 (heure de Paris)
  schedule:
    - cron: '0 7 * * 1'  # 7h UTC = 8h Paris (heure d'hiver) / 9h Paris (heure d'Ã©tÃ©)

  # ExÃ©cution manuelle Ã  la demande
  workflow_dispatch:

jobs:
  scrape-positions:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout du code
        uses: actions/checkout@v4

      - name: ğŸŸ¢ Installation de Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: ğŸ“¦ Installation des dÃ©pendances
        run: npm ci

      - name: ğŸ”‘ Configuration des credentials Google
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json

      - name: âš™ï¸ Configuration de l'environnement
        run: |
          echo "SPREADSHEET_ID=${{ secrets.SPREADSHEET_ID }}" >> .env
          echo "SHEET_NAME=${{ secrets.SHEET_NAME }}" >> .env
          echo "SERPAPI_KEY=${{ secrets.SERPAPI_KEY }}" >> .env
          echo "SERPAPI_KEY2=${{ secrets.SERPAPI_KEY2 }}" >> .env
          echo "TARGET_DOMAIN=fix-my-kea.com" >> .env

      - name: ğŸš€ ExÃ©cution du scraping avec SerpApi
        run: npm start
        env:
          NODE_ENV: production

      - name: ğŸ§¹ Nettoyage des credentials
        if: always()
        run: |
          rm -f credentials.json
          rm -f .env

      - name: âœ… Notification de succÃ¨s
        if: success()
        run: |
          echo "âœ… Scraping terminÃ© avec succÃ¨s!"
          echo "ğŸ“Š VÃ©rifiez votre Google Sheet pour les rÃ©sultats."

      - name: âŒ Notification d'Ã©chec
        if: failure()
        run: |
          echo "âŒ Le scraping a Ã©chouÃ©."
          echo "ğŸ“ Consultez les logs ci-dessus pour plus de dÃ©tails."
